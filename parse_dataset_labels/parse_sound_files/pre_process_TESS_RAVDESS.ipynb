{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597627574661",
   "display_name": "Python 3.7.5 64-bit ('venv2': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_file = \"../../databases/TESS_and_RAVDESS/Angry/03-01-05-01-01-01-01.wav\"\n",
    "\n",
    "# # sample rate is per second. 2 second video we have about 44,000 samples\n",
    "# signal, sr = librosa.load(sound_file, sr=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length=512, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = [180, -720, 50, -600, -450, -50, -100]\n",
    "# min_ = -720\n",
    "# max_ = 180\n",
    "# li = [2*((x-min_)/(max_-min_))-1 for x in li]\n",
    "# print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(mfcc)\n",
    "# x = 2*((mfcc-min_)/(max_-min_))-1\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sound_emotion_path = \"../../databases/TESS_and_RAVDESS/\"\n",
    "data = {\n",
    "    \"mfcc\": [],\n",
    "    \"label\": []\n",
    "}\n",
    "\n",
    "max_ = 0\n",
    "min_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sound(filename, dirpath, emotion, sample_rate, n_mfcc, n_fft, hop_length):\n",
    "    file_path = os.path.join(dirpath, filename)\n",
    "    # sample rate is per-second, signal.size/sample rate = time\n",
    "    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    # Option to round this so we get more samples, but having consistent 1 second samples is important too\n",
    "    intervals = int(signal.size / sample_rate)\n",
    "    for x in range(intervals):\n",
    "        start = x * sample_rate\n",
    "        stop = start + sample_rate\n",
    "        mfcc = librosa.feature.mfcc(signal[start:stop], sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=n_mfcc)\n",
    "        __ = max(max(mfcc.tolist()))\n",
    "        _ = min(min(mfcc.tolist()))\n",
    "        max_ = max(__, 0)\n",
    "        min_ = min(_, 0)\n",
    "\n",
    "        # Easier to work with\n",
    "        mfcc = mfcc.T\n",
    "        data[\"mfcc\"].append(mfcc.tolist())\n",
    "        data[\"label\"].append(emotion)\n",
    "        # The length of each mfcc should be equal because we need that in order to properly train on a 1 second-sample with a \n",
    "        # sample rate of 22050. If we change anything about the n_fft, or hop_length, we must re-process everything from scratch\n",
    "    return max_, min_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../../databases/TESS_and_RAVDESS/\n../../databases/TESS_and_RAVDESS/Angry\n../../databases/TESS_and_RAVDESS/Disgusted\n../../databases/TESS_and_RAVDESS/Fearful\n../../databases/TESS_and_RAVDESS/Happy\n../../databases/TESS_and_RAVDESS/Neutral\n../../databases/TESS_and_RAVDESS/Sad\n../../databases/TESS_and_RAVDESS/Suprised\n"
    }
   ],
   "source": [
    "def save_mfcc(dataset_path, n_mfcc=13, n_fft=1024, hop_length=256, sample_rate=22050):\n",
    "    # count: 0=Angry, 1=Disgusted, 2=Fearful, 3=Happy, 4=Netural, 5=Sad, 6=Surprised\n",
    "    for count, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        # print(filenames)\n",
    "        # print(dirnames)\n",
    "        print(dirpath)\n",
    "        if dirpath is not sound_emotion_path:\n",
    "            if \"Angry\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    max_, min_ = process_sound(f, dirpath, \"anger_disgust\", sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Disgusted\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    max_, min_ = process_sound(f, dirpath, \"anger_disgust\", sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Suprised\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    max_, min_ = process_sound(f, dirpath, \"surprised_fear\", sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Fearful\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    max_, min_ = process_sound(f, dirpath, \"surprised_fear\", sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Happy\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    max_, min_ = process_sound(f, dirpath, \"joy\", sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Sad\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    max_, min_ = process_sound(f, dirpath, \"sadness\", sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Neutral\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    max_, min_ = process_sound(f, dirpath, \"neutral\", sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            else:\n",
    "                continue\n",
    "    return max_, min_\n",
    "max_, min_ = save_mfcc(sound_emotion_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "57.107505798339844 -600.6202392578125\n"
    }
   ],
   "source": [
    "print(max_, min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# probably need to create a new json object \n",
    "# for x in data[\"mfcc\"]:\n",
    "#     arr = np.asarray(x)\n",
    "#     2*((arr-min_)/(max_-min_))-1\n",
    "#     data2[\"mfcc\"].append(arr.tolist())\n",
    "# print(data[\"mfcc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./tess_ravdess.json\", \"w\") as fp:\n",
    "    json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}