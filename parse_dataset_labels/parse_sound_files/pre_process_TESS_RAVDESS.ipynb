{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598075816251",
   "display_name": "Python 3.7.5 64-bit ('venv2': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_file = \"../../databases/TESS_and_RAVDESS/Angry/03-01-05-01-01-01-01.wav\"\n",
    "\n",
    "# # sample rate is per second. 2 second video we have about 44,000 samples\n",
    "# signal, sr = librosa.load(sound_file, sr=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length=512, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = [180, -720, 50, -600, -450, -50, -100]\n",
    "# min_ = -720\n",
    "# max_ = 180\n",
    "# li = [2*((x-min_)/(max_-min_))-1 for x in li]\n",
    "# print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(mfcc)\n",
    "# x = 2*((mfcc-min_)/(max_-min_))-1\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sound_emotion_path = \"../../databases/TESS_and_RAVDESS/\"\n",
    "train_data = {\n",
    "    \"mfcc\": [],\n",
    "    \"label\": [],\n",
    "    \"emotion\": []\n",
    "}\n",
    "\n",
    "validation_data = {\n",
    "    \"mfcc\": [],\n",
    "    \"label\": [],\n",
    "    \"emotion\": []\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"mfcc\": [],\n",
    "    \"label\": [],\n",
    "    \"emotion\": []\n",
    "}\n",
    "\n",
    "max_ = 0\n",
    "min_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sound(filename, dirpath, emotion, label, sample_rate, n_mfcc, n_fft, hop_length):\n",
    "    file_path = os.path.join(dirpath, filename)\n",
    "    # sample rate is per-second, signal.size/sample rate = time\n",
    "    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    # Option to round this so we get more samples, but having consistent 1 second samples is important too\n",
    "    intervals = int(signal.size / sample_rate)\n",
    "    for x in range(intervals):\n",
    "        start = x * sample_rate\n",
    "        stop = start + sample_rate\n",
    "        mfcc = librosa.feature.mfcc(signal[start:stop], sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=n_mfcc)\n",
    "        mfcc = mfcc.T\n",
    "\n",
    "        randint = random.random()\n",
    "        if randint < 0.8: \n",
    "            train_data[\"mfcc\"].append(mfcc.tolist())\n",
    "            train_data[\"label\"].append(label)\n",
    "            train_data[\"emotion\"].append(emotion)\n",
    "        elif randint >= 0.8 and randint < 0.9:\n",
    "            validation_data[\"mfcc\"].append(mfcc.tolist())\n",
    "            validation_data[\"label\"].append(label)\n",
    "            validation_data[\"emotion\"].append(emotion)            \n",
    "        else:       \n",
    "            test_data[\"mfcc\"].append(mfcc.tolist())\n",
    "            test_data[\"label\"].append(label)\n",
    "            test_data[\"emotion\"].append(emotion)              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../../databases/TESS_and_RAVDESS/\n../../databases/TESS_and_RAVDESS/Emotions\n../../databases/TESS_and_RAVDESS/Emotions\\Angry\n../../databases/TESS_and_RAVDESS/Emotions\\Disgusted\n../../databases/TESS_and_RAVDESS/Emotions\\Fearful\n../../databases/TESS_and_RAVDESS/Emotions\\Happy\n../../databases/TESS_and_RAVDESS/Emotions\\Neutral\n../../databases/TESS_and_RAVDESS/Emotions\\Sad\n../../databases/TESS_and_RAVDESS/Emotions\\Suprised\n"
    }
   ],
   "source": [
    "def save_mfcc(dataset_path, n_mfcc=13, n_fft=1024, hop_length=256, sample_rate=22050):\n",
    "    # count: 0=Angry, 1=Disgusted, 2=Fearful, 3=Happy, 4=Netural, 5=Sad, 6=Surprised\n",
    "    for count, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        # print(filenames)\n",
    "        # print(dirnames)\n",
    "        print(dirpath)\n",
    "        if dirpath is not sound_emotion_path:\n",
    "            if \"Angry\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    process_sound(f, dirpath, \"anger_disgust\", 0, sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Disgusted\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    process_sound(f, dirpath, \"anger_disgust\", 0, sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Suprised\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    process_sound(f, dirpath, \"surprised_fear\", 4, sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Fearful\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    process_sound(f, dirpath, \"surprised_fear\", 4, sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Happy\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    process_sound(f, dirpath, \"joy\", 1, sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Sad\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    process_sound(f, dirpath, \"sadness\", 3, sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            elif \"Neutral\" in dirpath:\n",
    "                for f in filenames:\n",
    "                    process_sound(f, dirpath, \"neutral\", 2, sample_rate, n_mfcc, n_fft, hop_length)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "save_mfcc(sound_emotion_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# probably need to create a new json object \n",
    "# for x in data[\"mfcc\"]:\n",
    "#     arr = np.asarray(x)\n",
    "#     2*((arr-min_)/(max_-min_))-1\n",
    "#     data2[\"mfcc\"].append(arr.tolist())\n",
    "# print(data[\"mfcc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./tess_ravdess_train.json\", \"w\") as fp:\n",
    "    json.dump(train_data, fp, indent=4)\n",
    "with open(\"./tess_ravdess_validation.json\", \"w\") as fp:\n",
    "    json.dump(validation_data, fp, indent=4)\n",
    "with open(\"./tess_ravdess_test.json\", \"w\") as fp:\n",
    "    json.dump(test_data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}