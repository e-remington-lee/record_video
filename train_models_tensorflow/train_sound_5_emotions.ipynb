{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599085966010",
   "display_name": "Python 3.7.5 64-bit ('venv2': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "%precision 4\n",
    "\n",
    "L2_WEIGHT_DECAY = 0.01\n",
    "L1_WEIGHT_DECAY = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    \n",
    "    a = np.array(data[\"mfcc\"])\n",
    "    label = np.array(data[\"label\"])\n",
    "\n",
    "    mfcc = a[..., np.newaxis]\n",
    "    print(mfcc.shape)\n",
    "\n",
    "    return mfcc, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(9661, 87, 1)\n(1186, 87, 1)\n(1194, 87, 1)\n"
    }
   ],
   "source": [
    "train_path = \"../parse_dataset_labels/parse_sound_files/tess_ravdess_train_norm.json\"\n",
    "validate_path = \"../parse_dataset_labels/parse_sound_files/tess_ravdess_validation_norm.json\"\n",
    "test_path = \"../parse_dataset_labels/parse_sound_files/tess_ravdess_test_norm.json\"\n",
    "\n",
    "# Gets the list from the json\n",
    "train_mfcc_list, train_label_list = load_json_data(train_path)\n",
    "validate_mfcc_list, validate_label_list = load_json_data(validate_path)\n",
    "test_mfcc_list, test_label_list = load_json_data(test_path)\n",
    "\n",
    "# Shuffles the list, unzips the list, creates numpy arrays from the lists\n",
    "x = list(zip(train_mfcc_list, train_label_list))\n",
    "random.shuffle(x)\n",
    "train_mfcc_tuple, train_label_tuple = zip(*x)\n",
    "train_mfcc = np.array(train_mfcc_tuple)\n",
    "train_label = np.array(train_label_tuple)\n",
    "\n",
    "# Shuffles the list, unzips the list, creates numpy arrays from the lists\n",
    "x = list(zip(validate_mfcc_list, validate_label_list))\n",
    "random.shuffle(x)\n",
    "validate_mfcc_tuple, validate_label_tuple = zip(*x)\n",
    "validate_mfcc = np.array(validate_mfcc_tuple)\n",
    "validate_label = np.array(validate_label_tuple)\n",
    "\n",
    "# Shuffles the list, unzips the list, creates numpy arrays from the lists\n",
    "x = list(zip(test_mfcc_list, test_label_list))\n",
    "random.shuffle(x)\n",
    "test_mfcc_tuple, test_label_tuple = zip(*x)\n",
    "test_mfcc = np.array(test_mfcc_tuple)\n",
    "test_label = np.array(test_label_tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1194, 5)\n"
    }
   ],
   "source": [
    "# abc = tf.keras.utils.to_categorical(train_label)\n",
    "# print(abc)\n",
    "train_label = tf.keras.utils.to_categorical(train_label)\n",
    "test_label = tf.keras.utils.to_categorical(test_label)\n",
    "validate_label = tf.keras.utils.to_categorical(validate_label)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"alexNet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 87, 1, 1)]        0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 22, 1, 96)         11712     \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 22, 1, 96)         384       \n_________________________________________________________________\nactivation (Activation)      (None, 22, 1, 96)         0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 11, 1, 96)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 1, 256)        614656    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 11, 1, 256)        1024      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 11, 1, 256)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 6, 1, 256)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 6, 1, 384)         2457984   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 6, 1, 384)         1536      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 6, 1, 384)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 6, 1, 384)         3686784   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 6, 1, 384)         1536      \n_________________________________________________________________\nactivation_3 (Activation)    (None, 6, 1, 384)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 6, 1, 256)         2457856   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 6, 1, 256)         1024      \n_________________________________________________________________\nactivation_4 (Activation)    (None, 6, 1, 256)         0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 3, 1, 256)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 768)               0         \n_________________________________________________________________\ndense (Dense)                (None, 4096)              3149824   \n_________________________________________________________________\ndense_1 (Dense)              (None, 4096)              16781312  \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 20485     \n=================================================================\nTotal params: 29,186,117\nTrainable params: 29,183,365\nNon-trainable params: 2,752\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# using the hop length and fft params we have 87 time steps with 13 values for each\n",
    "input_layer = tf.keras.layers.Input(shape=(87, 1, 1))\n",
    "x = tf.keras.layers.Conv2D(96, (11,11), strides=4, padding=\"same\", kernel_initializer='he_normal', bias_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_layer)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D((3,3), strides=2, padding=\"same\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, (5,5), padding=\"same\", kernel_initializer='he_normal', bias_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D((3,3), strides=2, padding=\"same\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(384, (5,5), padding=\"same\", kernel_initializer='he_normal', bias_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(384, (5,5), padding=\"same\", kernel_initializer='he_normal', bias_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, (5,5), padding=\"same\", kernel_initializer='he_normal', bias_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D((3,3), strides=2, padding=\"same\")(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(4096, activation=\"relu\", kernel_initializer='he_normal', bias_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "x = tf.keras.layers.Dense(4096, activation=\"relu\", kernel_initializer='he_normal', bias_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "x = tf.keras.layers.Dense(5, activation=\"softmax\", kernel_initializer='he_normal', bias_initializer=\"he_normal\")(x)\n",
    "\n",
    "model = Model(input_layer, x, name='alexNet')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = tf.keras.layers.Input(shape=(train_mfcc.shape[1], train_mfcc.shape[2], train_mfcc.shape[3]))\n",
    "# x = tf.keras.layers.Conv2D(96, (3,3), activation=\"relu\", kernel_initializer='he_normal', bias_initializer=\"he_normal\")(input_layer)\n",
    "# x = tf.keras.layers.MaxPool2D((3,3), strides=2, padding=\"same\")(x)\n",
    "# # Batch normalization standardizes the activations of the current layer and what activations get sent to the next layer. this helps\n",
    "# # the model converge a lot faster because it has normalized values flowing through the model\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", kernel_initializer='he_normal', bias_initializer=\"he_normal\")(x)\n",
    "# x = tf.keras.layers.MaxPool2D((3,3), strides=2, padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(512, (3,3), activation=\"relu\", kernel_initializer='he_normal', bias_initializer=\"he_normal\")(x)\n",
    "# x = tf.keras.layers.MaxPool2D((3,3), strides=2, padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "# x = tf.keras.layers.Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, decay=0.0001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_points = \"../checkpoint/checkpoint_sound.hb/\"\n",
    "check_point_dir = os.path.dirname(check_points)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=check_point_dir, verbose=1, monitor=\"val_acc\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n302/302 [==============================] - ETA: 0s - loss: 1.4345 - acc: 0.4457\nEpoch 00001: val_acc did not improve from 0.39292\n302/302 [==============================] - 5s 17ms/step - loss: 1.4345 - acc: 0.4457 - val_loss: 1.8171 - val_acc: 0.2850\nEpoch 2/100\n302/302 [==============================] - ETA: 0s - loss: 1.4192 - acc: 0.4525\nEpoch 00002: val_acc did not improve from 0.39292\n302/302 [==============================] - 5s 17ms/step - loss: 1.4192 - acc: 0.4525 - val_loss: 1.6126 - val_acc: 0.3735\nEpoch 3/100\n300/302 [============================>.] - ETA: 0s - loss: 1.4183 - acc: 0.4502\nEpoch 00003: val_acc did not improve from 0.39292\n302/302 [==============================] - 5s 17ms/step - loss: 1.4181 - acc: 0.4504 - val_loss: 1.7030 - val_acc: 0.3153\nEpoch 4/100\n300/302 [============================>.] - ETA: 0s - loss: 1.4087 - acc: 0.4595\nEpoch 00004: val_acc did not improve from 0.39292\n302/302 [==============================] - 5s 17ms/step - loss: 1.4082 - acc: 0.4599 - val_loss: 1.8796 - val_acc: 0.2858\nEpoch 5/100\n301/302 [============================>.] - ETA: 0s - loss: 1.4070 - acc: 0.4572\nEpoch 00005: val_acc did not improve from 0.39292\n302/302 [==============================] - 5s 17ms/step - loss: 1.4070 - acc: 0.4572 - val_loss: 2.1317 - val_acc: 0.3035\nEpoch 6/100\n300/302 [============================>.] - ETA: 0s - loss: 1.4116 - acc: 0.4606\nEpoch 00006: val_acc did not improve from 0.39292\n302/302 [==============================] - 5s 17ms/step - loss: 1.4122 - acc: 0.4599 - val_loss: 1.5350 - val_acc: 0.3921\nEpoch 7/100\n301/302 [============================>.] - ETA: 0s - loss: 1.4023 - acc: 0.4631\nEpoch 00007: val_acc did not improve from 0.39292\n302/302 [==============================] - 5s 17ms/step - loss: 1.4029 - acc: 0.4629 - val_loss: 1.6264 - val_acc: 0.3710\nEpoch 8/100\n302/302 [==============================] - ETA: 0s - loss: 1.4126 - acc: 0.4555\nEpoch 00008: val_acc improved from 0.39292 to 0.41062, saving model to ../checkpoint/checkpoint_sound.hb\nINFO:tensorflow:Assets written to: ../checkpoint/checkpoint_sound.hb\\assets\n302/302 [==============================] - 8s 27ms/step - loss: 1.4126 - acc: 0.4555 - val_loss: 1.4806 - val_acc: 0.4106\nEpoch 9/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3918 - acc: 0.4735\nEpoch 00009: val_acc did not improve from 0.41062\n302/302 [==============================] - 5s 17ms/step - loss: 1.3915 - acc: 0.4733 - val_loss: 1.6978 - val_acc: 0.3558\nEpoch 10/100\n301/302 [============================>.] - ETA: 0s - loss: 1.3910 - acc: 0.4766\nEpoch 00010: val_acc did not improve from 0.41062\n302/302 [==============================] - 5s 18ms/step - loss: 1.3907 - acc: 0.4769 - val_loss: 1.8676 - val_acc: 0.3331\nEpoch 11/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3867 - acc: 0.4744\nEpoch 00011: val_acc did not improve from 0.41062\n302/302 [==============================] - 6s 18ms/step - loss: 1.3866 - acc: 0.4751 - val_loss: 1.9589 - val_acc: 0.3651\nEpoch 12/100\n302/302 [==============================] - ETA: 0s - loss: 1.3804 - acc: 0.4801\nEpoch 00012: val_acc did not improve from 0.41062\n302/302 [==============================] - 6s 19ms/step - loss: 1.3804 - acc: 0.4801 - val_loss: 1.8138 - val_acc: 0.3364\nEpoch 13/100\n301/302 [============================>.] - ETA: 0s - loss: 1.3852 - acc: 0.4766\nEpoch 00013: val_acc did not improve from 0.41062\n302/302 [==============================] - 5s 17ms/step - loss: 1.3849 - acc: 0.4767 - val_loss: 1.6124 - val_acc: 0.3727\nEpoch 14/100\n299/302 [============================>.] - ETA: 0s - loss: 1.3675 - acc: 0.4820\nEpoch 00014: val_acc did not improve from 0.41062\n302/302 [==============================] - 5s 17ms/step - loss: 1.3677 - acc: 0.4819 - val_loss: 1.8383 - val_acc: 0.2943\nEpoch 15/100\n302/302 [==============================] - ETA: 0s - loss: 1.3832 - acc: 0.4855\nEpoch 00015: val_acc did not improve from 0.41062\n302/302 [==============================] - 5s 18ms/step - loss: 1.3832 - acc: 0.4855 - val_loss: 1.7036 - val_acc: 0.3634\nEpoch 16/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3672 - acc: 0.4872\nEpoch 00016: val_acc improved from 0.41062 to 0.44266, saving model to ../checkpoint/checkpoint_sound.hb\nINFO:tensorflow:Assets written to: ../checkpoint/checkpoint_sound.hb\\assets\n302/302 [==============================] - 8s 27ms/step - loss: 1.3669 - acc: 0.4871 - val_loss: 1.4456 - val_acc: 0.4427\nEpoch 17/100\n301/302 [============================>.] - ETA: 0s - loss: 1.3681 - acc: 0.4899\nEpoch 00017: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3678 - acc: 0.4899 - val_loss: 1.6960 - val_acc: 0.3752\nEpoch 18/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3766 - acc: 0.4883\nEpoch 00018: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3765 - acc: 0.4885 - val_loss: 1.6210 - val_acc: 0.3524\nEpoch 19/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3667 - acc: 0.4878\nEpoch 00019: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3680 - acc: 0.4873 - val_loss: 1.7558 - val_acc: 0.3769\nEpoch 20/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3539 - acc: 0.4926\nEpoch 00020: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3541 - acc: 0.4928 - val_loss: 1.7031 - val_acc: 0.3583\nEpoch 21/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3497 - acc: 0.4967\nEpoch 00021: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3498 - acc: 0.4965 - val_loss: 1.6300 - val_acc: 0.3693\nEpoch 22/100\n302/302 [==============================] - ETA: 0s - loss: 1.3656 - acc: 0.4956\nEpoch 00022: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3656 - acc: 0.4956 - val_loss: 1.9247 - val_acc: 0.3027\nEpoch 23/100\n302/302 [==============================] - ETA: 0s - loss: 1.3517 - acc: 0.4960\nEpoch 00023: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3517 - acc: 0.4960 - val_loss: 1.6746 - val_acc: 0.3432\nEpoch 24/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3454 - acc: 0.5027\nEpoch 00024: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3457 - acc: 0.5026 - val_loss: 1.7228 - val_acc: 0.3592\nEpoch 25/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3407 - acc: 0.5049\nEpoch 00025: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3399 - acc: 0.5054 - val_loss: 1.7120 - val_acc: 0.3870\nEpoch 26/100\n301/302 [============================>.] - ETA: 0s - loss: 1.3333 - acc: 0.5080\nEpoch 00026: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3337 - acc: 0.5076 - val_loss: 1.5621 - val_acc: 0.4073\nEpoch 27/100\n299/302 [============================>.] - ETA: 0s - loss: 1.3344 - acc: 0.5142\nEpoch 00027: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3343 - acc: 0.5138 - val_loss: 1.9098 - val_acc: 0.2960\nEpoch 28/100\n300/302 [============================>.] - ETA: 0s - loss: 1.3270 - acc: 0.5215\nEpoch 00028: val_acc did not improve from 0.44266\n302/302 [==============================] - 5s 17ms/step - loss: 1.3277 - acc: 0.5205 - val_loss: 1.7437 - val_acc: 0.3449\nEpoch 29/100\n241/302 [======================>.......] - ETA: 1s - loss: 1.3377 - acc: 0.5101"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3dd308c02840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         callbacks=[cp_callback])\n\u001b[0m",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Coding\\real_time_video_classifier\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_mfcc, train_label, \n",
    "        validation_data=(validate_mfcc, validate_label), \n",
    "        verbose=1, \n",
    "        batch_size=32, \n",
    "        epochs=100,\n",
    "        callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}